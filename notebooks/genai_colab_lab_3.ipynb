{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Environment\n",
        "The following code loads the environment variables required to run this notebook.\n"
      ],
      "metadata": {
        "id": "45iKqhTIUkjf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SO7q2oWEURVE"
      },
      "outputs": [],
      "source": [
        "FILE=\"GenAI Lab 3\"\n",
        "\n",
        "! pip install -qqq git+https://github.com/elastic/notebook-workshop-loader.git@main\n",
        "from notebookworkshoploader import loader\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "if os.path.isfile(\"../env\"):\n",
        "    load_dotenv(\"../env\", override=True)\n",
        "    print('Successfully loaded environment variables from local env file')\n",
        "else:\n",
        "    loader.load_remote_env(file=FILE, env_url=\"https://notebook-workshop-api-voldmqr2bq-uc.a.run.app\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq langchain==0.1.3 sentence-transformers==2.2.2 beautifulsoup4==4.11.2\n",
        "!pip install -qqq tiktoken==0.5.2 cohere==4.38 openai==1.3.9\n",
        "!pip install -qqq matplotlib==3.7.1 scikit-learn==1.2.2 scipy==1.11.4\n",
        "!pip install -qqq elasticsearch==8.12.0 inquirer==3.2.1\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "y2eoZ4hCUud2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from elasticsearch import Elasticsearch\n",
        "if 'ELASTIC_CLOUD_ID' in os.environ:\n",
        "  es = Elasticsearch(\n",
        "    cloud_id=os.environ['ELASTIC_CLOUD_ID'],\n",
        "    api_key=(os.environ['ELASTIC_APIKEY_ID'], os.environ['ELASTIC_APIKEY_SECRET']),\n",
        "    request_timeout=30\n",
        "  )\n",
        "elif 'ELASTIC_URL' in os.environ:\n",
        "  es = Elasticsearch(\n",
        "    os.environ['ELASTIC_URL'],\n",
        "    api_key=(os.environ['ELASTIC_APIKEY_ID'], os.environ['ELASTIC_APIKEY_SECRET']),\n",
        "    request_timeout=30\n",
        "  )\n",
        "else:\n",
        "  print(\"env needs to set either ELASTIC_CLOUD_ID or ELASTIC_URL\")"
      ],
      "metadata": {
        "id": "kpsGUDWAX42B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, secrets, requests\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from requests.auth import HTTPBasicAuth\n",
        "\n",
        "#if using the Elastic AI proxy, then generate the correct API key\n",
        "if os.environ['ELASTIC_PROXY'] == \"True\":\n",
        "\n",
        "    if \"OPENAI_API_TYPE\" in os.environ: del os.environ[\"OPENAI_API_TYPE\"]\n",
        "\n",
        "    #generate and share \"your\" unique hash\n",
        "    os.environ['USER_HASH'] = secrets.token_hex(nbytes=6)\n",
        "    print(f\"Your unique user hash is: {os.environ['USER_HASH']}\")\n",
        "\n",
        "    #get the current API key and combine with your hash\n",
        "    os.environ['OPENAI_API_KEY'] = f\"{os.environ['OPENAI_API_KEY']} {os.environ['USER_HASH']}\"\n",
        "else:\n",
        "    openai.api_type = os.environ['OPENAI_API_TYPE']\n",
        "    openai.api_version = os.environ['OPENAI_API_VERSION']\n",
        "\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']\n",
        "openai.api_base = os.environ['OPENAI_API_BASE']\n",
        "openai.default_model = os.environ['OPENAI_API_ENGINE']"
      ],
      "metadata": {
        "id": "59sPX8_HETbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 : Simple vectorization using a Vector Embedding model installed to Elasticsearch\n",
        "[Model Card - msmarco-MiniLM-L-12-v3](https://huggingface.co/sentence-transformers/msmarco-MiniLM-L-12-v3). - note this model has a 512 token limit"
      ],
      "metadata": {
        "id": "iWXrus6La0wF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es_model_id = 'sentence-transformers__msmarco-minilm-l-12-v3'\n",
        "\n",
        "## use REST call to Elastic to generate Vector Embedding, assumes model is already installed\n",
        "def sentence_to_vector_es(chunk, es_model_id=es_model_id):\n",
        "  docs =  [{\"text_field\": chunk}]\n",
        "  chunk_vector = es.ml.infer_trained_model(model_id=es_model_id, docs=docs, )\n",
        "  return chunk_vector['inference_results'][0]['predicted_value']\n",
        "\n",
        "\n",
        "chunk = \"The quick brown fox jumped over the lazy dog\"\n",
        "es_generated_vector = sentence_to_vector_es(chunk)\n",
        "print(f\"Dimensions: {len(es_generated_vector)}, \\nVector preview: {es_generated_vector[:5]+ ['...']}\")"
      ],
      "metadata": {
        "id": "Sqo3T-LlY_Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Vectoring Data using a local E5 model and Sentence Transformer\n",
        "\n",
        "[Model card E5-large-v2](https://huggingface.co/intfloat/e5-large-v2)"
      ],
      "metadata": {
        "id": "El7UrXMcgnns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sentence_transformers import SentenceTransformer\n",
        "e5_model = SentenceTransformer('intfloat/e5-large-v2')\n",
        "input_texts = [\n",
        "    'query: how much protein should a female human eat',\n",
        "    'query: summit define',\n",
        "    \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
        "    \"passage: Definition of summit for English Language Learners. : 1  the highest point of a mountain : the top of a mountain. : 2  the highest level. : 3  a meeting or series of meetings between the leaders of two or more governments.\"\n",
        "]\n",
        "embeddings = e5_model.encode(input_texts, normalize_embeddings=True)\n",
        "close=\" ...]\"\n",
        "print(f\"Dimensions: {len(embeddings[0])}, \\nVector preview: {str(embeddings[0][:5])[:-1]+close}\")"
      ],
      "metadata": {
        "id": "q6a7y24zeBnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Doing the same thing but with the LangChain Utility libraries"
      ],
      "metadata": {
        "id": "hVZMHggOg4Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "langchain_e5_embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/e5-large-v2\")\n",
        "input_texts = [\n",
        "    'query: how much protein should a female human eat',\n",
        "    'query: summit define',\n",
        "    \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
        "    \"passage: Definition of summit for English Language Learners. : 1  the highest point of a mountain : the top of a mountain. : 2  the highest level. : 3  a meeting or series of meetings between the leaders of two or more governments.\"\n",
        "]\n",
        "embeddings = langchain_e5_embeddings.embed_documents(input_texts)\n",
        "close=\", ...]\"\n",
        "print(f\"Dimensions: {len(embeddings[0])}, \\nVector preview: {str(embeddings[0][:5])[:-1]+close}\")"
      ],
      "metadata": {
        "id": "x14UmhoMe6J4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Let's create a simplified graph of generated Embeddings\n",
        "\n",
        "Principal Component analysis can be used to simplify higher dimesions into a 2d plot.\n"
      ],
      "metadata": {
        "id": "fIBODndAhoH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch the model and load it\n",
        "word_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "print(\"Model dimensions:\", word_model.get_sentence_embedding_dimension())\n",
        "\n",
        "# generate embeddings\n",
        "embeddings_for_cat = word_model.encode(\"cat\")\n",
        "embeddings_for_kitten = word_model.encode(\"kitten\")\n",
        "embeddings_for_dog = word_model.encode(\"dog\")\n",
        "embeddings_for_puppy = word_model.encode(\"puppy\")\n",
        "embeddings_for_lawnmower = word_model.encode(\"lawnmower\")\n",
        "\n",
        "# let's see what we got, though truncate the embeddings to just the first 5 dimensions\n",
        "print(f\"embedding dimensions: {embeddings_for_cat.size}\")\n",
        "print(f\"cat: {list(embeddings_for_cat)[:5] + ['...']}\")\n",
        "print(f\"dog: {list(embeddings_for_dog)[:5] + ['...']}\")"
      ],
      "metadata": {
        "id": "_J1dTm5OiCuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import altair as alt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# wrap embeddings with a DataFrame\n",
        "df = pd.DataFrame(\n",
        "    [\n",
        "      [embeddings_for_cat],\n",
        "      [embeddings_for_kitten],\n",
        "      [embeddings_for_dog],\n",
        "      [embeddings_for_puppy],\n",
        "      [embeddings_for_lawnmower],\n",
        "    ],\n",
        "    index=[\"cat\", \"kitten\", \"dog\", \"puppy\", \"lawnmower\"], columns=[\"embeddings\"]\n",
        ")\n",
        "\n",
        "# Initialize the PCA reducer to convert embeddings into arrays of length of 2\n",
        "reducer = PCA(n_components=2)\n",
        "\n",
        "# Reduce the embeddings, store them in a new dataframe column and display their shape\n",
        "df[\"reduced\"] = reducer.fit_transform(np.stack(df[\"embeddings\"])).tolist()\n",
        "\n",
        "\n",
        "def scatterplot(\n",
        "    data: pd.DataFrame,\n",
        "    tooltips=False,\n",
        "    labels=False,\n",
        "    width=800,\n",
        "    height=600,\n",
        ") -> alt.Chart:\n",
        "    base_chart = (\n",
        "        alt.Chart(data)\n",
        "        .encode(\n",
        "            alt.X(\"x\", scale=alt.Scale(zero=False)),\n",
        "            alt.Y(\"y\", scale=alt.Scale(zero=False)),\n",
        "        )\n",
        "        .properties(width=width, height=height)\n",
        "    )\n",
        "\n",
        "    if tooltips:\n",
        "        base_chart = base_chart.encode(alt.Tooltip([\"text\"]))\n",
        "\n",
        "    circles = base_chart.mark_circle(\n",
        "        size=200, color=\"crimson\", stroke=\"white\", strokeWidth=1\n",
        "    )\n",
        "\n",
        "    if labels:\n",
        "        labels = base_chart.mark_text(\n",
        "            fontSize=13,\n",
        "            align=\"left\",\n",
        "            baseline=\"bottom\",\n",
        "            dx=5,\n",
        "        ).encode(text=\"text\")\n",
        "        chart = circles + labels\n",
        "    else:\n",
        "        chart = circles\n",
        "\n",
        "    return chart\n",
        "\n",
        "source = pd.DataFrame(\n",
        "    {\n",
        "        \"text\": df.index,\n",
        "        \"x\": df[\"reduced\"].apply(lambda x: x[0]).to_list(),\n",
        "        \"y\": df[\"reduced\"].apply(lambda x: x[1]).to_list(),\n",
        "    }\n",
        ")\n",
        "\n",
        "scatterplot(source, labels=True,  width=400, height=300)"
      ],
      "metadata": {
        "id": "edsUVexdhsKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5 - using the more advanced e5 model, see that questions can be matched with answers"
      ],
      "metadata": {
        "id": "yLrQl_eKnbjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## using e5_model previously loaded\n",
        "input_texts = [\n",
        "    'query: how much protein should a female human eat',\n",
        "    'query: summit define',\n",
        "    \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
        "    \"passage: Definition of summit for English Language Learners. : 1  the highest point of a mountain : the top of a mountain. : 2  the highest level. : 3  a meeting or series of meetings between the leaders of two or more governments.\",\n",
        "    \"passage: I am the very model of a modern Major-General / I've information vegetable, animal, and mineral / I know the kings of England, and I quote the fights historical / From Marathon to Waterloo, in order categorical / I'm very well acquainted, too, with matters mathematical\",\n",
        "    \"passage: When, in the course of human events, it becomes necessary for one people to dissolve the political bands which have connected them with another, and to assume, among the powers of the earth\",\n",
        "    \"passage: It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\",\n",
        "]\n",
        "embeddings = e5_model.encode(input_texts, normalize_embeddings=True)\n",
        "\n",
        "\n",
        "# let's see what we got, though truncate the embeddings to just the first 5 dimensions\n",
        "print(f\"embedding dimensions: {embeddings[0].size}\")\n",
        "print(f\"first query: {list(embeddings[0])[:3] + ['...']}\")\n",
        "\n",
        "\n",
        "# wrap embeddings with a DataFrame\n",
        "df = pd.DataFrame(\n",
        "    [\n",
        "      [embeddings[0]],\n",
        "      [embeddings[1]],\n",
        "      [embeddings[2]],\n",
        "      [embeddings[3]],\n",
        "      [embeddings[4]],\n",
        "      [embeddings[5]],\n",
        "      [embeddings[6]],\n",
        "    ],\n",
        "    index=[\n",
        "        \"q: protein\",\n",
        "        \"q: summit\",\n",
        "        \"p: protein guide\",\n",
        "        \"p: summit def\",\n",
        "        \"p: penzanse\",\n",
        "        \"p: dec of ind\",\n",
        "        \"p: austen\"\n",
        "        ], columns=[\"embeddings\"]\n",
        ")\n",
        "\n",
        "# Initialize the PCA reducer to convert embeddings into arrays of length of 2\n",
        "reducer = PCA(n_components=2)\n",
        "\n",
        "# Reduce the embeddings, store them in a new dataframe column and display their shape\n",
        "df[\"reduced\"] = reducer.fit_transform(np.stack(df[\"embeddings\"])).tolist()\n",
        "\n",
        "source = pd.DataFrame(\n",
        "    {\n",
        "        \"text\": df.index,\n",
        "        \"x\": df[\"reduced\"].apply(lambda x: x[0]).to_list(),\n",
        "        \"y\": df[\"reduced\"].apply(lambda x: x[1]).to_list(),\n",
        "    }\n",
        ")\n",
        "\n",
        "scatterplot(source, labels=True,  width=400, height=300)"
      ],
      "metadata": {
        "id": "GXkl-MA7kyQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6 : calculate the actual distance in 1024 dimensional space"
      ],
      "metadata": {
        "id": "738GN3qE2lM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance\n",
        "\n",
        "passages = [\n",
        "    \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
        "    \"passage: Definition of summit for English Language Learners. : 1  the highest point of a mountain : the top of a mountain. : 2  the highest level. : 3  a meeting or series of meetings between the leaders of two or more governments.\",\n",
        "    \"passage: I am the very model of a modern Major-General / I've information vegetable, animal, and mineral / I know the kings of England, and I quote the fights historical / From Marathon to Waterloo, in order categorical / I'm very well acquainted, too, with matters mathematical\",\n",
        "    \"passage: When, in the course of human events, it becomes necessary for one people to dissolve the political bands which have connected them with another, and to assume, among the powers of the earth\",\n",
        "    \"passage: It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\",\n",
        "]\n",
        "\n",
        "def chunks_by_distance(passages, query_text, model):\n",
        "  embeddings = model.encode(passages, normalize_embeddings=True)\n",
        "  query_embedding = model.encode(query_text, normalize_embeddings=True)\n",
        "  distances = []\n",
        "  for index, passage in enumerate(passages):\n",
        "    cos_distance = distance.cosine(embeddings[index], query_embedding)\n",
        "    distances.append((passage, cos_distance))\n",
        "  sorted_passages = sorted(distances, key=lambda x: x[1])\n",
        "\n",
        "  return sorted_passages\n",
        "\n",
        "protein_query = 'query: how much protein should a female human eat'\n",
        "sorted_passages = chunks_by_distance(passages, protein_query, e5_model)\n",
        "\n",
        "for passage, dist in sorted_passages:\n",
        "      print(f\"{passage[:40]} - Cosine distance {dist:.12f}\")\n"
      ],
      "metadata": {
        "id": "QKAT1UBAzZfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OKAY let's work with an actual large document"
      ],
      "metadata": {
        "id": "fTRQlTcO_jC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wikipedia_spacecraft = [\n",
        "{\n",
        "  \"id\": \"37910\",\n",
        "  \"title\": \"Spacecraft\",\n",
        "  \"text\": \"A spacecraft is a vehicle that is designed to fly in outer space. A type of artificial satellite, spacecraft are used for a variety of purposes, including communications, Earth observation, meteorology, navigation, space colonization, planetary exploration, and transportation of humans and cargo. All spacecraft except single-stage-to-orbit vehicles cannot get into space on their own, and require a launch vehicle (carrier rocket). On a sub-orbital spaceflight, a space vehicle enters space and then returns to the surface without having gained sufficient energy or velocity to make a full Earth orbit. For orbital spaceflights, spacecraft enter closed orbits around the Earth or around other celestial bodies. Spacecraft used for human spaceflight carry people on board as crew or passengers from start or on orbit (space stations) only, whereas those used for robotic space missions operate either autonomously or telerobotically. Robotic spacecraft used to support scientific research are space probes. Robotic spacecraft that remain in orbit around a planetary body are artificial satellites. To date, only a handful of interstellar probes, such as Pioneer 10 and 11, Voyager 1 and 2, and New Horizons, are on trajectories that leave the Solar System. Orbital spacecraft may be recoverable or not. Most are not. Recoverable spacecraft may be subdivided by a method of reentry to Earth into non-winged space capsules and winged spaceplanes. Recoverable spacecraft may be reusable (can be launched again or several times, like the SpaceX Dragon and the Space Shuttle orbiters) or expendable (like the Soyuz). In recent years, more space agencies are tending towards reusable spacecraft. Humanity has achieved space flight, but only a few nations have the technology for orbital launches: Russia (RSA or \\\"Roscosmos\\\"), the United States (NASA), the member states of the European Space Agency (ESA), Japan (JAXA), China (CNSA), India (ISRO), Taiwan National Chung-Shan Institute of Science and Technology, Taiwan National Space Organization (NSPO), Israel (ISA), Iran (ISA), and North Korea (NADA). In addition, several private companies have developed or are developing the technology for orbital launches independently from government agencies. The most prominent examples of such companies are SpaceX and Blue Origin. ==History== A German V-2 became the first spacecraft when it reached an altitude of 189 km in June 1944 in Peenemünde, Germany.Peenemünde (Dokumentation) Berlin: Moewig, 1984.. Sputnik 1 was the first artificial satellite. It was launched into an elliptical low Earth orbit (LEO) by the Soviet Union on 4 October 1957. The launch ushered in new political, military, technological, and scientific developments; while the Sputnik launch was a single event, it marked the start of the Space Age.Dougall, Walter A. (Winter 2010) \\\"Shooting the duck\\\", American Heritage Apart from its value as a technological first, Sputnik 1 also helped to identify the upper atmospheric layer's density, by measuring the satellite's orbital changes. It also provided data on radio-signal distribution in the ionosphere. Pressurized nitrogen in the satellite's false body provided the first opportunity for meteoroid detection. Sputnik 1 was launched during the International Geophysical Year from Site No.1/5, at the 5th Tyuratam range, in Kazakh SSR (now at the Baikonur Cosmodrome). The satellite travelled at , taking 96.2 minutes to complete an orbit, and emitted radio signals at 20.005 and 40.002 MHz While Sputnik 1 was the first spacecraft to orbit the Earth, other human- made objects had previously reached an altitude of 100 km, which is the height required by the international organization Fédération Aéronautique Internationale to count as a spaceflight. This altitude is called the Kármán line. In particular, in the 1940s there were several test launches of the V-2 rocket, some of which reached altitudes well over 100 km. ==Spacecraft types== ===Crewed spacecraft=== thumb|Apollo 17 command module in Lunar orbit As of 2016, only three nations have flown crewed spacecraft: USSR/Russia, USA, and China. The first crewed spacecraft was Vostok 1, which carried Soviet cosmonaut Yuri Gagarin into space in 1961, and completed a full Earth orbit. There were five other crewed missions which used a Vostok spacecraft. The second crewed spacecraft was named Freedom 7, and it performed a sub-orbital spaceflight in 1961 carrying American astronaut Alan Shepard to an altitude of just over . There were five other crewed missions using Mercury spacecraft. Other Soviet crewed spacecraft include the Voskhod, Soyuz, flown uncrewed as Zond/L1, L3, TKS, and the Salyut and Mir crewed space stations. Other American crewed spacecraft include the Gemini spacecraft, the Apollo spacecraft including the Apollo Lunar Module, the Skylab space station, the Space Shuttle with undetached European Spacelab and private US Spacehab space stations- modules, and the SpaceX Crew Dragon configuration of their Dragon 2. US company Boeing also developed and flown a spacecraft of their own, the CST-100, commonly referred to as Starliner, but a crewed flight is yet to occur. China developed, but did not fly Shuguang, and is currently using Shenzhou (its first crewed mission was in 2003). Except for the Space Shuttle, all of the recoverable crewed orbital spacecraft were space capsules. File:NASA spacecraft comparison.jpg|alt=Drawings of Mercury, Gemini capsules and Apollo spacecraft, with their launch vehicles|American Mercury, Gemini, and Apollo spacecraft File:Vostok Spacecraft Diagram.svg|Soviet Vostok capsule File:Voskhod 1 and 2.svg|alt=Line drawing of Voskhod capsules|Soviet Voskhod (variant of Vostok) File:Soyuz 7K-OK(A) drawing.svg|alt=Soyuz 7K-OK(A) drawing|1967 Soviet/Russian Soyuz spacecraft File:Post S-7 Shenzhou spacecraft.png|alt=Drawing of Shenzhou spacecraft|Chinese Shenzhou spacecraft The International Space Station, crewed since November 2000, is a joint venture between Russia, the United States, Canada and several other countries. ====Spaceplanes==== thumb|Columbia orbiter landing Spaceplanes are spacecraft that are built in the shape of, and function as, airplanes. The first example of such was the North American X-15 spaceplane, which conducted two crewed flights which reached an altitude of over 100 km in the 1960s. This first reusable spacecraft was air-launched on a suborbital trajectory on July 19, 1963. The first partially reusable orbital spacecraft, a winged non-capsule, the Space Shuttle, was launched by the USA on the 20th anniversary of Yuri Gagarin's flight, on April 12, 1981. During the Shuttle era, six orbiters were built, all of which have flown in the atmosphere and five of which have flown in space. Enterprise was used only for approach and landing tests, launching from the back of a Boeing 747 SCA and gliding to deadstick landings at Edwards AFB, California. The first Space Shuttle to fly into space was Columbia, followed by Challenger, Discovery, Atlantis, and Endeavour. Endeavour was built to replace Challenger when it was lost in January 1986. Columbia broke up during reentry in February 2003. The first automatic partially reusable spacecraft was the Buran-class shuttle, launched by the USSR on November 15, 1988, although it made only one flight and this was uncrewed. This spaceplane was designed for a crew and strongly resembled the U.S. Space Shuttle, although its drop-off boosters used liquid propellants and its main engines were located at the base of what would be the external tank in the American Shuttle. Lack of funding, complicated by the dissolution of the USSR, prevented any further flights of Buran. The Space Shuttle was subsequently modified to allow for autonomous re-entry in case of necessity. Per the Vision for Space Exploration, the Space Shuttle was retired in 2011 mainly due to its old age and high cost of program reaching over a billion dollars per flight. The Shuttle's human transport role is to be replaced by SpaceX's SpaceX Dragon 2 and Boeing's CST-100 Starliner. Dragon 2's first crewed flight occurred on May 30, 2020. The Shuttle's heavy cargo transport role is to be replaced by expendable rockets such as the Space Launch System and ULA's Vulcan rocket, as well as the commercial launch vehicles. Scaled Composites' SpaceShipOne was a reusable suborbital spaceplane that carried pilots Mike Melvill and Brian Binnie on consecutive flights in 2004 to win the Ansari X Prize. The Spaceship Company will build its successor SpaceShipTwo. A fleet of SpaceShipTwos operated by Virgin Galactic was planned to begin reusable private spaceflight carrying paying passengers in 2014, but was delayed after the crash of VSS Enterprise. ===Uncrewed spacecraft=== Uncrewed spacecraft are spacecraft without people on board. Uncrewed spacecraft may have varying levels of autonomy from human input; they may be remote controlled, remote guided or even autonomous, meaning they have a pre-programmed list of operations, which they will execute unless otherwise instructed. Many space missions are more suited to telerobotic rather than crewed operation, due to lower cost and lower risk factors. In addition, some planetary destinations such as Venus or the vicinity of Jupiter are too hostile for human survival. Outer planets such as Saturn, Uranus, and Neptune are too distant to reach with current crewed spaceflight technology, so telerobotic probes are the only way to explore them. Telerobotics also allows exploration of regions that are vulnerable to contamination by Earth micro-organisms since spacecraft can be sterilized. Humans can not be sterilized in the same way as a spaceship, as they coexist with numerous micro-organisms, and these micro-organisms are also hard to contain within a spaceship or spacesuit. Multiple space probes were sent to study Moon, the planets, the Sun, multiple small Solar System bodies (comets and asteroids). Special class of uncrewed spacecraft is space telescopes, a telescope in outer space used to observe astronomical objects. The first operational telescopes were the American Orbiting Astronomical Observatory, OAO-2 launched in 1968, and the Soviet Orion 1 ultraviolet telescope aboard space station Salyut 1 in 1971. Space telescopes avoid the filtering and distortion (scintillation) of electromagnetic radiation which they observe, and avoid light pollution which ground-based observatories encounter. The best-known examples are Hubble Space Telescope and James Webb Space Telescope. Cargo spacecraft are designed to carry cargo, possibly to support space stations' operation by transporting food, propellant and other supplies. Automated cargo spacecraft have been used since 1978 and have serviced Salyut 6, Salyut 7, Mir, the International Space Station and Tiangong space station. ====Fastest spacecraft==== *Parker Solar Probe (estimated at first sun close pass, will reach at final perihelion) *Helios I and II Solar Probes () ==== Furthest spacecraft from the Sun ==== * Voyager 1 at 156.13 AU as of April 2022, traveling outward at about * Pioneer 10 at 122.48 AU as of December 2018, traveling outward at about *Voyager 2 at 122.82 AU as of January 2020, traveling outward at about *Pioneer 11 at 101.17 AU as of December 2018, traveling outward at about ==Subsystems== A spacecraft astrionics system comprises different subsystems, depending on the mission profile. Spacecraft subsystems comprise the spacecraft's bus and may include attitude determination and control (variously called ADAC, ADC, or ACS), guidance, navigation and control (GNC or GN&C;), communications (comms), command and data handling (CDH or C&DH;), power (EPS), thermal control (TCS), propulsion, and structures. Attached to the bus are typically payloads. ; Life support : Spacecraft intended for human spaceflight must also include a life support system for the crew. ; Attitude control : A Spacecraft needs an attitude control subsystem to be correctly oriented in space and respond to external torques and forces properly. The attitude control subsystem consists of sensors and actuators, together with controlling algorithms. The attitude- control subsystem permits proper pointing for the science objective, sun pointing for power to the solar arrays and earth pointing for communications. ; GNC : Guidance refers to the calculation of the commands (usually done by the CDH subsystem) needed to steer the spacecraft where it is desired to be. Navigation means determining a spacecraft's orbital elements or position. Control means adjusting the path of the spacecraft to meet mission requirements. ; Command and data handling : The C&DH; subsystem receives commands from the communications subsystem, performs validation and decoding of the commands, and distributes the commands to the appropriate spacecraft subsystems and components. The CDH also receives housekeeping data and science data from the other spacecraft subsystems and components, and packages the data for storage on a data recorder or transmission to the ground via the communications subsystem. Other functions of the CDH include maintaining the spacecraft clock and state-of-health monitoring. ; Communications : Spacecraft, both robotic and crewed, have various communications systems for communication with terrestrial stations and for inter-satellite service. Technologies include space radio station and optical communication. In addition, some spacecraft payloads are explicitly for the purpose of ground–ground communication using receiver/retransmitter electronic technologies. ; Power : Spacecraft need an electrical power generation and distribution subsystem for powering the various spacecraft subsystems. For spacecraft near the Sun, solar panels are frequently used to generate electrical power. Spacecraft designed to operate in more distant locations, for example Jupiter, might employ a radioisotope thermoelectric generator (RTG) to generate electrical power. Electrical power is sent through power conditioning equipment before it passes through a power distribution unit over an electrical bus to other spacecraft components. Batteries are typically connected to the bus via a battery charge regulator, and the batteries are used to provide electrical power during periods when primary power is not available, for example when a low Earth orbit spacecraft is eclipsed by Earth. ; Thermal control : Spacecraft must be engineered to withstand transit through Earth's atmosphere and the space environment. They must operate in a vacuum with temperatures potentially ranging across hundreds of degrees Celsius as well as (if subject to reentry) in the presence of plasmas. Material requirements are such that either high melting temperature, low density materials such as beryllium and reinforced carbon–carbon or (possibly due to the lower thickness requirements despite its high density) tungsten or ablative carbon–carbon composites are used. Depending on mission profile, spacecraft may also need to operate on the surface of another planetary body. The thermal control subsystem can be passive, dependent on the selection of materials with specific radiative properties. Active thermal control makes use of electrical heaters and certain actuators such as louvers to control temperature ranges of equipments within specific ranges. ; Spacecraft propulsion : Spacecraft may or may not have a propulsion subsystem, depending on whether or not the mission profile calls for propulsion. The Swift spacecraft is an example of a spacecraft that does not have a propulsion subsystem. Typically though, LEO spacecraft include a propulsion subsystem for altitude adjustments (drag make-up maneuvers) and inclination adjustment maneuvers. A propulsion system is also needed for spacecraft that perform momentum management maneuvers. Components of a conventional propulsion subsystem include fuel, tankage, valves, pipes, and thrusters. The thermal control system interfaces with the propulsion subsystem by monitoring the temperature of those components, and by preheating tanks and thrusters in preparation for a spacecraft maneuver. ; Structures : Spacecraft must be engineered to withstand launch loads imparted by the launch vehicle, and must have a point of attachment for all the other subsystems. Depending on mission profile, the structural subsystem might need to withstand loads imparted by entry into the atmosphere of another planetary body, and landing on the surface of another planetary body. ; Payload : The payload depends on the mission of the spacecraft, and is typically regarded as the part of the spacecraft \\\"that pays the bills\\\". Typical payloads could include scientific instruments (cameras, telescopes, or particle detectors, for example), cargo, or a human crew. ; Ground segment : The ground segment, though not technically part of the spacecraft, is vital to the operation of the spacecraft. Typical components of a ground segment in use during normal operations include a mission operations facility where the flight operations team conducts the operations of the spacecraft, a data processing and storage facility, ground stations to radiate signals to and receive signals from the spacecraft, and a voice and data communications network to connect all mission elements. ; Launch vehicle : The launch vehicle propels the spacecraft from Earth's surface, through the atmosphere, and into an orbit, the exact orbit being dependent on the mission configuration. The launch vehicle may be expendable or reusable. ==See also== *Astrionics *Commercial astronaut *Flying saucer *List of crewed spacecraft *List of fictional spacecraft *NewSpace *Spacecraft design *Space exploration *Space launch *Spaceships in science fiction *Space suit *Spaceflight records *Starship *Timeline of Solar System exploration *U.S. Space Exploration History on U.S. Stamps == References == === Citations === === Sources === * * ==External links== *NASA: Space Science Spacecraft Missions *NSSDC Master Catalog Spacecraft Query Form *Early History of Spacecraft *Basics of Spaceflight tutorial from JPL/Caltech *International Spaceflight Museum Category:Astronautics Category:Pressure vessels\",\n",
        "  \"categories\": [\n",
        "    \"Astronautics\",\n",
        "    \"Pressure vessels\"\n",
        "  ]\n",
        "},\n",
        " ]"
      ],
      "metadata": {
        "id": "oxo004rhYcDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Truncation is a problem for long texts\n",
        "\n",
        "The semantic relevance will be low because most of the text is ignored in the vector computation."
      ],
      "metadata": {
        "id": "0dwj-z5z7tnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text =        wikipedia_spacecraft[0][\"text\"]\n",
        "embeddings =  e5_model.encode(text, normalize_embeddings=True)\n",
        "\n",
        "tokenized_text =        e5_model.tokenizer(text)[\"input_ids\"]\n",
        "model_max_seq_length =  e5_model.get_max_seq_length()\n",
        "text_token_count =      len(tokenized_text)\n",
        "\n",
        "print(f\"text tokens {text_token_count} | model max sequence length {model_max_seq_length}\")\n",
        "\n",
        "if text_token_count > model_max_seq_length:\n",
        "    print(f\"❗❗ The text will be truncated.❗❗\")\n",
        "else:\n",
        "    print(f\"The text will not be truncated.\")"
      ],
      "metadata": {
        "id": "xUYUyZ4G3-ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Visualizing Chunking Strategies\n",
        "\n",
        "First some utility libraries"
      ],
      "metadata": {
        "id": "g0e_QS-i8rkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import json\n",
        "import textwrap\n",
        "from pprint import pprint\n",
        "from bs4 import BeautifulSoup\n",
        "from IPython.display import HTML\n",
        "#from elasticsearch import Elasticsearch, helpers\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, \\\n",
        "  SentenceTransformersTokenTextSplitter, \\\n",
        "  CharacterTextSplitter, \\\n",
        "  TextSplitter\n",
        "\n",
        "## Process splitting and display\n",
        "def split_and_print(documents, splitter, ret=False):\n",
        "    es_docs = []\n",
        "    for doc in documents:\n",
        "        passages = []\n",
        "\n",
        "        for chunk in splitter.split_text(doc['text']):\n",
        "            passages.append({\n",
        "                \"text\": chunk,\n",
        "            })\n",
        "        es_docs.append(passages)\n",
        "\n",
        "    print(f'Number of chunks: {len(passages)}' + '\\n')\n",
        "    display(HTML(process_chunks(passages)))\n",
        "    if ret:\n",
        "      return passages\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "\n",
        "## Character Splitter\n",
        "def split_by_recursive_char(documents,\n",
        "                  chunk_size: int = 200,\n",
        "                  chunk_overlap: int = 0\n",
        "                  ):\n",
        "    '''Chunking by character count'''\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        length_function=len,\n",
        "        is_separator_regex=False,\n",
        "    )\n",
        "    split_and_print(documents, text_splitter)\n",
        "\n",
        "\n",
        "def split_by_text(documents,\n",
        "                  chunk_size: int = 200,\n",
        "                  chunk_overlap: int = 0\n",
        "                  ):\n",
        "    '''Chunking by character count'''\n",
        "\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        length_function=len,\n",
        "        is_separator_regex=False,\n",
        "    )\n",
        "    r = split_and_print(documents, text_splitter)\n",
        "\n",
        "\n",
        "\n",
        "## Token Splitter\n",
        "def split_by_token(documents,\n",
        "                  tokens_per_chunk: int = 2,\n",
        "                  chunk_overlap: int = 0,\n",
        "                  ret=False\n",
        "                 ):\n",
        "    '''Chunking by BERT Transformer Tokens'''\n",
        "\n",
        "    text_splitter = SentenceTransformersTokenTextSplitter(\n",
        "        tokens_per_chunk=tokens_per_chunk,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        model_name='intfloat/e5-large-v2' # 512 token input limit\n",
        "    )\n",
        "    r = split_and_print(documents, text_splitter, ret=ret)\n",
        "    if ret:\n",
        "      return r\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Printing and Highlighting functions ##\n",
        "\n",
        "color_list = [\n",
        "    \"yellow\",\n",
        "    \"red\",\n",
        "    \"lightgreen\",\n",
        "    \"lightblue\",\n",
        "    \"lightpink\",\n",
        "    \"#F0A3FF\",  # Vivid orchid\n",
        "    \"#0075DC\",  # Blue ribbon\n",
        "    \"#2BCE48\",  # Slimy green\n",
        "    \"#FFCC99\",  # Peach-orange\n",
        "    \"#94FFB5\",  # Mint green\n",
        "\n",
        "]\n",
        "\n",
        "def find_overlap(text1, text2):\n",
        "    min_len = min(len(text1), len(text2))\n",
        "    for i in range(min_len, 0, -1):\n",
        "        if text1[-i:] == text2[:i]:\n",
        "            return text1[-i:]\n",
        "    return ''\n",
        "\n",
        "###################################################################################\n",
        "# Highted text -> White\n",
        "# Normal text -> Black\n",
        "\n",
        "### Uncomment these 3 functions if you are running in light mode\n",
        "\n",
        "# def highlight_first_occurrence(text, substring, color):\n",
        "#     index = text.find(substring)\n",
        "#     if index != -1:\n",
        "#         return (text[:index] +\n",
        "#                 f\"<span style='background-color: {color};'>{text[index:index+len(substring)]}</span>\" +\n",
        "#                 text[index+len(substring):])\n",
        "#     return text\n",
        "\n",
        "# def highlight_last_occurrence(text, substring, color):\n",
        "#     index = text.rfind(substring)\n",
        "#     if index != -1:\n",
        "#         return (text[:index] +\n",
        "#                 f\"<span style='background-color: {color};'>{text[index:index+len(substring)]}</span>\" +\n",
        "#                 text[index+len(substring):])\n",
        "#     return text\n",
        "\n",
        "# def process_chunks(chunks, colors=color_list):\n",
        "#     html_output = \"\"\n",
        "#     for i in range(len(chunks) - 1):\n",
        "#         overlap = find_overlap(chunks[i][\"text\"], chunks[i + 1][\"text\"])\n",
        "#         color = colors[i % len(colors)]  # Cycle through the provided colors\n",
        "#         if overlap:\n",
        "#             chunks[i][\"text\"] = highlight_last_occurrence(chunks[i][\"text\"], overlap, color)\n",
        "#             chunks[i + 1][\"text\"] = highlight_first_occurrence(chunks[i + 1][\"text\"], overlap, color)\n",
        "#         html_output += chunks[i][\"text\"] + \"<br><br>\"\n",
        "#     html_output += chunks[-1][\"text\"]  # Add the last chunk\n",
        "#     return html_output\n",
        "\n",
        "###################################################################################\n",
        "# Highted text -> Black\n",
        "# Normal text -> White\n",
        "\n",
        "### Comment out these 3 functions if running in light modes\n",
        "\n",
        "def highlight_first_occurrence(text, substring, color):\n",
        "    index = text.find(substring)\n",
        "    if index != -1:\n",
        "        return (text[:index] +\n",
        "                f\"<span style='background-color: {color}; color: black;'>{text[index:index+len(substring)]}</span>\" +\n",
        "                text[index+len(substring):])\n",
        "    return text\n",
        "\n",
        "def highlight_last_occurrence(text, substring, color):\n",
        "    index = text.rfind(substring)\n",
        "    if index != -1:\n",
        "        return (text[:index] +\n",
        "                f\"<span style='background-color: {color}; color: black;'>{text[index:index+len(substring)]}</span>\" +\n",
        "                text[index+len(substring):])\n",
        "    return text\n",
        "\n",
        "\n",
        "chunk_max_display = 10\n",
        "\n",
        "def process_chunks(chunks, colors=color_list):\n",
        "    html_output = \"\"\n",
        "    for i in range(min(chunk_max_display -1,len(chunks) - 1)):\n",
        "        overlap = find_overlap(chunks[i][\"text\"], chunks[i + 1][\"text\"])\n",
        "        color = colors[i % len(colors)]  # Cycle through the provided colors\n",
        "        if overlap:\n",
        "            chunks[i][\"text\"] = highlight_last_occurrence(chunks[i][\"text\"], overlap, color)\n",
        "            chunks[i + 1][\"text\"] = highlight_first_occurrence(chunks[i + 1][\"text\"], overlap, color)\n",
        "        # Wrap each chunk of text in a span with white text color\n",
        "        html_output += f\"<span style='color: gray;'>{chunks[i]['text']}</span><br><br>\"\n",
        "    # Add the last chunk with white text color\n",
        "    html_output += f\"<span style='color: gray;'>{chunks[-1]['text']}</span>\"\n",
        "    html_output += f\"<br/><br/><span style='color: gray;'>... additional chunks omitted</span>\"\n",
        "    return html_output"
      ],
      "metadata": {
        "id": "OSMKdU-d8yzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9: Three Chunking Strategies\n",
        "\n",
        "[LangChain recursive character text splitter](https://python.langchain.com/docs/modules/data_connection/document_transformers/recursive_text_splitter)\n",
        "\n",
        "[LangChain splitting by tokens](https://python.langchain.com/docs/modules/data_connection/document_transformers/split_by_token)"
      ],
      "metadata": {
        "id": "TZbfLoQhRFXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_by_recursive_char(wikipedia_spacecraft, chunk_size=1024, chunk_overlap=0)"
      ],
      "metadata": {
        "id": "b0ClYN7K9NF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_by_recursive_char(wikipedia_spacecraft, chunk_size=1024, chunk_overlap=50)"
      ],
      "metadata": {
        "id": "GXAMcK2I9vop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_c500_o0 = split_by_token(wikipedia_spacecraft, tokens_per_chunk=500, chunk_overlap=0, ret=True)"
      ],
      "metadata": {
        "id": "LKliFbbn97ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_c500_o250 = split_by_token(wikipedia_spacecraft, tokens_per_chunk=500, chunk_overlap=100, ret=True)"
      ],
      "metadata": {
        "id": "aAI1bgTR-ZXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 10: Let's comapare using the whole passage vs the best chunk with ChatGPT"
      ],
      "metadata": {
        "id": "BUApSzG6SXfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "the_full_text = wikipedia_spacecraft[0][\"text\"]\n",
        "\n",
        "question = \"What three countries have flown manned spacecraft?\"\n",
        "\n",
        "def gen_system_prompt(context):\n",
        "  return f\"\"\"You are an AI assistant than answers questions based on the provided context.\n",
        "Use only the provided context.  If the provided context does not have the answer\n",
        "reply only with 'I do not know'\n",
        "\n",
        "Context: {context}\"\"\"\n",
        "\n",
        "import textwrap\n",
        "# wrap text when printing, because colab scrolls output to the right too much\n",
        "def wrap_text(text, width):\n",
        "    wrapped_text = textwrap.wrap(text, width)\n",
        "    return '\\n'.join(wrapped_text)\n",
        "\n",
        "def print_light_blue(text):\n",
        "    print(f'\\033[94m{text}\\033[0m')\n",
        "\n",
        "def chatCompletion(messages):\n",
        "\n",
        "    client = OpenAI(api_key=openai.api_key, base_url=openai.api_base)\n",
        "    completion = client.chat.completions.create(\n",
        "        model=openai.default_model,\n",
        "        max_tokens=150,\n",
        "        messages=messages\n",
        "    )\n",
        "    print_light_blue(f\"\\t{completion.usage}\")\n",
        "\n",
        "    return completion\n",
        "\n",
        "def chatWithSpacePassage(prompt, context):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": gen_system_prompt(context)},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "      ]\n",
        "    print_light_blue(\"Prompt:\")\n",
        "    print_light_blue(wrap_text(messages[1][\"content\"],70))\n",
        "    completion = chatCompletion(messages)\n",
        "\n",
        "    response_text = completion.choices[0].message.content\n",
        "\n",
        "    return wrap_text(response_text,70)\n",
        "\n",
        "\n",
        "ai_response = chatWithSpacePassage(question, the_full_text)\n",
        "\n",
        "print(ai_response)\n"
      ],
      "metadata": {
        "id": "xpjUDLUKEtSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 11: Reducing LLM inference costs by 91%\n",
        "\n",
        "We'll deep dive into how to use Elasticearch to speed up the vector search and other kinds of Search Powered AI in the next part of the workshop.\n",
        "\n"
      ],
      "metadata": {
        "id": "nI6AQ0ACSZ9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the_full_text = wikipedia_spacecraft[0][\"text\"]\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=50,\n",
        "    length_function=len\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_text(the_full_text)\n",
        "\n",
        "## Vectorizing can take time so I'm only processing the first few chunks\n",
        "sorted_chunks = chunks_by_distance(chunks[:5], question, e5_model)\n",
        "\n",
        "## top 3 chunk distances\n",
        "for passage, dist in sorted_chunks[:3]:\n",
        "  print(f\"{passage[:40]} - Cosine distance {dist:.12f}\")\n",
        "print(\"\")\n",
        "\n",
        "top_passage = sorted_chunks[0][0]\n",
        "print(wrap_text(top_passage, 70))\n",
        "print(\"\")\n",
        "\n",
        "ai_response = chatWithSpacePassage(question, top_passage)\n",
        "print(ai_response)"
      ],
      "metadata": {
        "id": "RD6Znhd7Gfiu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}